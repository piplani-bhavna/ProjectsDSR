{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Extracting all headers from \"http://en.wikipedia.org/wiki/Main_Page?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing reqd libraries\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying all the header tags\n",
    "def AllHeaders(url):\n",
    "    if requests.get(url):\n",
    "        html =urlopen(url)\n",
    "        bs = BeautifulSoup(html, \"html.parser\")\n",
    "        titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "        print('Listing all header tags :', *titles, sep='\\n')\n",
    "        \n",
    "    else:\n",
    "        print(\"Web Scraping Denied\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listing all header tags :\n",
      "<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "<h2>Navigation menu</h2>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span>Personal tools</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span>Namespaces</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
      "<span>Variants</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span>Views</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
      "<span>More</span>\n",
      "</h3>\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span>Navigation</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span>Contribute</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span>Tools</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span>Print/export</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span>In other projects</span>\n",
      "</h3>\n",
      "<h3 class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span>Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "AllHeaders(\"http://en.wikipedia.org/wiki/Main_Page?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. IMDB Top rated  100 Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lodaing the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from random import randint\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top100Movies(url):\n",
    "    # Creating the lists we want to write into\n",
    "    titles = []\n",
    "    years = []\n",
    "    imdb_ratings = []\n",
    "    #pages we need is the first page with 1-50 and second from 51-100\n",
    "    pages = np.arange(1, 101, 50)\n",
    "    \n",
    "    # Getting English translated titles from the movies\n",
    "    headers = {'Accept-Language': 'en-US, en;q=0.5'}\n",
    "\n",
    "    if requests.get(url):\n",
    "        \n",
    "        #initialising the page with main page having no page count in url\n",
    "        page = requests.get(url , headers=headers)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "        # Aiming the part of the html we want to get the information from\n",
    "        movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "        for container in movie_div:\n",
    "            # Scraping the movie's name\n",
    "            name = container.h3.a.text\n",
    "            titles.append(name)\n",
    "        \n",
    "            # Scraping the movie's year\n",
    "            year = container.h3.find('span', class_='lister-item-year').text\n",
    "            years.append(year)\n",
    "        \n",
    "        \n",
    "            # Scraping the rating\n",
    "            imdb = float(container.strong.text)\n",
    "            imdb_ratings.append(imdb)\n",
    "            \n",
    "        for page in pages:\n",
    "            # Getting the contents from the each url\n",
    "            page=requests.get(url + '&start='  + str(page) + '&ref_=adv_nxt', headers=headers)\n",
    "            soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "            # Aiming the part of the html we want to get the information from\n",
    "            movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "    \n",
    "            # Controling the loop’s rate by pausing the execution of the loop for a specified amount of time\n",
    "            # Waiting time between requests for a number between 2-10 seconds\n",
    "        sleep(randint(2,10))\n",
    "        \n",
    "        for container in movie_div:\n",
    "            # Scraping the movie's name\n",
    "            name = container.h3.a.text\n",
    "            titles.append(name)\n",
    "        \n",
    "            # Scraping the movie's year\n",
    "            year = container.h3.find('span', class_='lister-item-year').text\n",
    "            years.append(year)\n",
    "        \n",
    "        \n",
    "            # Scraping the rating\n",
    "            imdb = float(container.strong.text)\n",
    "            imdb_ratings.append(imdb)\n",
    "            \n",
    "        #saving the data in Dataframe\n",
    "        movies = pd.DataFrame({'MovieName':titles,\n",
    "                       'Year of Release':years,\n",
    "                       'IMDB Rating':imdb_ratings,\n",
    "                       })\n",
    "\n",
    "            # Cleaning 'year' column\n",
    "        movies['Year of Release'] = movies['Year of Release'].str.extract('(\\d+)').astype(int)\n",
    "        print(movies)\n",
    "        movies.to_csv(\"Top100Movies.csv\")\n",
    "    else:\n",
    "        print(\"Web Scraping denied\")\n",
    "\n",
    "\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   MovieName  Year of Release  IMDB Rating\n",
      "0   The Shawshank Redemption             1994          9.3\n",
      "1              The Godfather             1972          9.2\n",
      "2            The Dark Knight             2008          9.0\n",
      "3     The Godfather: Part II             1974          9.0\n",
      "4               12 Angry Men             1957          9.0\n",
      "..                       ...              ...          ...\n",
      "95                   Vertigo             1958          8.3\n",
      "96       Singin' in the Rain             1952          8.3\n",
      "97              Citizen Kane             1941          8.3\n",
      "98                         M             1931          8.3\n",
      "99                   The Kid             1921          8.3\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "Top100Movies(\"https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. IMDb top 100 Indian Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top100IndianMovies(web_url):\n",
    " \n",
    "    list_of_titles = []\n",
    "    list_of_years = []\n",
    "    user_ratings = []\n",
    " \n",
    "    source = requests.get(web_url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    " \n",
    "    print(soup.title.text)\n",
    " \n",
    "    tbody = soup.tbody\n",
    "    table_rows = tbody.find_all('tr')\n",
    " \n",
    "    for td in table_rows:\n",
    "        titles_column = td.find_all('td', class_=\"titleColumn\")\n",
    "        imdb_ratings = td.find_all('td', class_=\"ratingColumn imdbRating\")\n",
    "  \n",
    "        for information in titles_column:\n",
    "            title = information.a.text\n",
    "            list_of_titles.append(title)\n",
    "            year = information.span.text\n",
    "            list_of_years.append(year)\n",
    "        \n",
    "        for rating in imdb_ratings:\n",
    "            user_rating = rating.text.strip()\n",
    "            user_ratings.append(user_rating)\n",
    "        \n",
    "    #saving the data in Dataframe\n",
    "    movies = pd.DataFrame({'MovieName':list_of_titles,\n",
    "                       'Year of Release':list_of_years,\n",
    "                       'IMDB Rating':user_ratings,\n",
    "                       })\n",
    "\n",
    "    # Cleaning 'year' column\n",
    "    movies['Year of Release'] = movies['Year of Release'].str.extract('(\\d+)').astype(int)\n",
    "    print(movies[0:100])\n",
    "    movies.to_csv(\"Top100IndianMovies.csv\")        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Rated Indian Movies - IMDb\n",
      "                     MovieName  Year of Release IMDB Rating\n",
      "0              Pather Panchali             1955         8.5\n",
      "1                     Gol Maal             1979         8.5\n",
      "2                      Nayakan             1987         8.5\n",
      "3                   Anbe Sivam             2003         8.5\n",
      "4                   Drishyam 2             2021         8.5\n",
      "..                         ...              ...         ...\n",
      "95  The Legend of Bhagat Singh             2002         8.0\n",
      "96                  Bommarillu             2006         8.0\n",
      "97                     Maqbool             2003         8.0\n",
      "98                      Bombay             1995         8.0\n",
      "99                      Omkara             2006         8.0\n",
      "\n",
      "[100 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "Top100IndianMovies(\"https://www.imdb.com/india/top-rated-indian-movies/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Scraping from ‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#book name, author name, genre and book review of any 5 books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bookPage(url):\n",
    "    \n",
    "    Book_Name=[]\n",
    "    Author_Name=[]\n",
    "    Genre=[]\n",
    "    b_Review=[]\n",
    "    \n",
    "    # Getting English translated titles from the movies\n",
    "    headers = {'Accept-Language': 'en-US, en;q=0.5'}\n",
    "    \n",
    "    if requests.get(url):\n",
    "        page=requests.get(url,headers=headers)\n",
    "        print(page)\n",
    "        soup=BeautifulSoup(page.text,'html.parser')\n",
    "        \n",
    "        book_div=soup.find_all('div',class_='flex-article-content')\n",
    "        \n",
    "        for container in book_div:\n",
    "            #scraping book name\n",
    "            bname=container.h4.a.text\n",
    "            Book_Name.append(bname)\n",
    "            \n",
    "            # Scraping the author name\n",
    "            aName = container.find('p', class_='sans bold').text\n",
    "            Author_Name.append(aName)\n",
    "            #Book_Name.strip()\n",
    "            \n",
    "            #scraping genre\n",
    "            genre=container.find('p',class_='genre-links hidden-phone')\n",
    "            Genre.append(genre)\n",
    "            #Genre.strip()\n",
    "            \n",
    "            #scraping review\n",
    "            review=container.find('p',class_='excerpt')\n",
    "            b_Review.append(review)\n",
    "            #b_Review.strip()\n",
    "            \n",
    "        books=pd.DataFrame({'Book Name':Book_Name ,'Author Name':Author_Name,\n",
    "                           'Genre' : Genre,'Reviews': b_Review})    \n",
    "        \n",
    "        print(books)\n",
    "    else:\n",
    "        print(\"Web Access Denied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "                                  Book Name  \\\n",
      "0        Brother, Sister, Mother, Explorer    \n",
      "1             The Sweet Taste of Muscadines   \n",
      "2                     ★ We Begin at the End   \n",
      "3                      Creatures of Passage   \n",
      "4                             Body of Stars   \n",
      "5                                  My Heart   \n",
      "6                       The Arsonists' City   \n",
      "7  The Phone Booth at the Edge of the World   \n",
      "8                         ★ The Seed Keeper   \n",
      "9                   ★ How Beautiful We Were   \n",
      "\n",
      "                                    Author Name  \\\n",
      "0                            \\nJamie Figueroa\\n   \n",
      "1                              \\nPamela Terry\\n   \n",
      "2                            \\nChris Whitaker\\n   \n",
      "3                             \\nMorowa Yejidé\\n   \n",
      "4                      \\nLaura Maylene Walter\\n   \n",
      "5  \\nSemezdin Mehmedinovic, Celia Hawkesworth\\n   \n",
      "6                                \\nHala Alyan\\n   \n",
      "7             \\nLaura Imai Messina, Lucy Rand\\n   \n",
      "8                              \\nDiane Wilson\\n   \n",
      "9                               \\nImbolo Mbue\\n   \n",
      "\n",
      "                                               Genre  \\\n",
      "0   [\\n, [Fiction], \\n / \\n, [Literary Fiction], \\n]   \n",
      "1       [\\n, [Fiction], \\n / \\n, [Family Drama], \\n]   \n",
      "2      [\\n, [Fiction], \\n / \\n, [Crime Fiction], \\n]   \n",
      "3  [\\n, [Fiction], \\n / \\n, [Speculative Fiction]...   \n",
      "4  [\\n, [Fiction], \\n / \\n, [Dystopian Fiction], \\n]   \n",
      "5        [\\n, [Fiction], \\n / \\n, [Autofiction], \\n]   \n",
      "6       [\\n, [Fiction], \\n / \\n, [Family Drama], \\n]   \n",
      "7   [\\n, [Fiction], \\n / \\n, [Literary Fiction], \\n]   \n",
      "8   [\\n, [Fiction], \\n / \\n, [Literary Fiction], \\n]   \n",
      "9   [\\n, [Fiction], \\n / \\n, [Literary Fiction], \\n]   \n",
      "\n",
      "                                             Reviews  \n",
      "0  [\\nGhosts hover over Jamie Figueroa’s debut, a...  \n",
      "1  [\\nPamela Terry’s debut novel sometimes feels ...  \n",
      "2  [\\nChris Whitaker combines a brisk pace, a sol...  \n",
      "3  [\\nThis contemporary fairy tale’s grandeur and...  \n",
      "4  [\\n, [In the circumscribed dystopia of Laura M...  \n",
      "5  [\\n, [The poet and songwriter Leonard Cohen on...  \n",
      "6  [\\nHala Alyan, who is a family therapist as we...  \n",
      "7  [\\n, [The Phone Booth at the Edge of the World...  \n",
      "8  [\\nThe story of a bold, strong Dakhóta woman n...  \n",
      "9  [\\nReaders who enjoyed , [Behold the Dreamers]...  \n"
     ]
    }
   ],
   "source": [
    "bookPage(\"https://bookpage.com/reviews?book_genre=fiction&page=1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. (i) Scraping Top 10 ODI Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top10ODIMenTeam(url):\n",
    "    \n",
    "    Team_Name = []\n",
    "    Matches = []\n",
    "    Points = []\n",
    "    Ratings=[]\n",
    "    \n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    " \n",
    "    print(soup.title.text)\n",
    " \n",
    "    tbody = soup.tbody\n",
    "    table_rows = tbody.find_all('tr')\n",
    " \n",
    "    for td in table_rows:\n",
    "        Team_col = td.find_all('span', class_=\"u-hide-phablet\")\n",
    "        Match_col = td.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "        Point_col= td.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "        Ratings_col= td.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    " \n",
    "        for i in Team_col:\n",
    "            Tname = i.text\n",
    "            Team_Name.append(Tname)\n",
    "            del Team_Name[19:]\n",
    "        \n",
    "        for i in Match_col:\n",
    "            \n",
    "            Matches.append(Match_col[0].text)\n",
    "            Points.append(Match_col[1].text)\n",
    "            Match_col.pop(0)\n",
    "            del Points[19:38]\n",
    "        \n",
    "                    \n",
    "        for i in Ratings_col:\n",
    "            rating=i.text.strip()\n",
    "            Ratings.append(rating)\n",
    "            \n",
    "            \n",
    "       \n",
    "    #saving the data in Dataframe\n",
    "    teams = pd.DataFrame({'Team_Name':Team_Name,\n",
    "                       'YMatches':Matches,\n",
    "                       'Points':Points,'Ratings':Ratings\n",
    "                       })\n",
    "\n",
    "    print(teams[0:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC Ranking for ODI teams International Cricket Council\n",
      "      Team_Name YMatches Points Ratings\n",
      "0       England       52  6,102     117\n",
      "1         India       33  3,857     117\n",
      "2   New Zealand       39  4,344     111\n",
      "3     Australia       31  3,345     108\n",
      "4  South Africa       35  3,490     100\n",
      "5      Pakistan       38  3,432      90\n",
      "6    Bangladesh       42  3,372      80\n",
      "7     Sri Lanka       49  3,802      78\n",
      "8   West Indies       31  1,844      59\n",
      "9   Afghanistan       29  1,316      45\n"
     ]
    }
   ],
   "source": [
    "Top10ODIMenTeam(\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. (ii) scraping top 10 Batsman in ODI "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top10BatsmanODI(url):\n",
    "    Batsman_Name = []\n",
    "    Team = []\n",
    "    Ratings=[]\n",
    "    \n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    " \n",
    "    print(soup.title.text)\n",
    " \n",
    "    tbody = soup.tbody\n",
    "    table_rows = tbody.find_all('tr')\n",
    " \n",
    "    for td in table_rows:\n",
    "        batsman_col = td.find_all('td', class_=\"table-body__cell name\")\n",
    "        Team_col = td.find_all('span', class_=\"table-body__logo-text\")\n",
    "        Ratings_col= td.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    " \n",
    "        for i in batsman_col:\n",
    "            name = i.a.text\n",
    "            Batsman_Name.append(name)\n",
    "            \n",
    "        for i in Team_col:\n",
    "            team=i.text.strip()\n",
    "            Team.append(team)\n",
    "            \n",
    "        for i in Ratings_col:\n",
    "            rating=i.text.strip()\n",
    "            Ratings.append(rating)\n",
    "            \n",
    "            \n",
    "     \n",
    "    #saving the data in Dataframe\n",
    "    batsman = pd.DataFrame({'Batsman Name':Batsman_Name,\n",
    "                       'Team':Team,\n",
    "                       'Ratings':Ratings\n",
    "                       })\n",
    "\n",
    "    print(batsman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC ODI Match Player Rankings International Cricket Council\n",
      "          Batsman Name Team Ratings\n",
      "0         Rohit Sharma  IND     842\n",
      "1           Babar Azam  PAK     837\n",
      "2          Ross Taylor   NZ     818\n",
      "3          Aaron Finch  AUS     791\n",
      "4  Francois du Plessis   SA     790\n",
      "5         David Warner  AUS     773\n",
      "6            Shai Hope   WI     773\n",
      "7      Kane Williamson   NZ     765\n",
      "8      Quinton de Kock   SA     755\n"
     ]
    }
   ],
   "source": [
    "Top10BatsmanODI(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. (iii) scraping top 10 bowlers in ODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top10BowlersODI(url):\n",
    "    BowlerName = []\n",
    "    Team = []\n",
    "    Ratings=[]\n",
    "    \n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    " \n",
    "    print(soup.title.text)\n",
    " \n",
    "    tbody = soup.tbody\n",
    "    table_rows = tbody.find_all('tr')\n",
    "    main_div=soup.find_all('div',{\"class\":\"rankings-block__container\",\"data-cricket-role\":\"bowling\"})\n",
    "        \n",
    "    for td in main_div:\n",
    "        bowler_col = td.find_all('td', class_=\"table-body__cell name\")\n",
    "        Team_col = td.find_all('span', class_=\"table-body__logo-text\")\n",
    "        Ratings_col= td.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    " \n",
    "        for i in bowler_col:\n",
    "            name = i.a.text\n",
    "            BowlerName.append(name)\n",
    "            \n",
    "        for i in Team_col:\n",
    "            team=i.text.strip()\n",
    "            Team.append(team)\n",
    "            \n",
    "        for i in Ratings_col:\n",
    "            rating=i.text.strip()\n",
    "            Ratings.append(rating)\n",
    "            \n",
    "            \n",
    "    #saving the data in Dataframe\n",
    "    bowlers = pd.DataFrame({'Bowler Name':BowlerName,\n",
    "                       'Team':Team,\n",
    "                       'Ratings':Ratings\n",
    "                       })\n",
    "\n",
    "    print(bowlers[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC ODI Match Player Rankings International Cricket Council\n",
      "         Bowler Name Team Ratings\n",
      "0   Mujeeb Ur Rahman  AFG     708\n",
      "1     Jasprit Bumrah  IND     700\n",
      "2       Mehedi Hasan  BAN     694\n",
      "3       Chris Woakes  ENG     675\n",
      "4      Kagiso Rabada   SA     665\n",
      "5     Josh Hazlewood  AUS     660\n",
      "6  Mustafizur Rahman  BAN     658\n",
      "7      Mohammad Amir  PAK     647\n",
      "8        Pat Cummins  AUS     646\n",
      "9   Mujeeb Ur Rahman  AFG     708\n"
     ]
    }
   ],
   "source": [
    "Top10BowlersODI(\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. (i) scraping top 10 ODI teams (women)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top10ODIWomenTeam(url):\n",
    "    \n",
    "    Team_Name = []\n",
    "    Matches = []\n",
    "    Points = []\n",
    "    Ratings=[]\n",
    "    \n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    " \n",
    "    print(soup.title.text)\n",
    " \n",
    "    tbody = soup.tbody\n",
    "    table_rows = tbody.find_all('tr')\n",
    " \n",
    "    for td in table_rows:\n",
    "        Team_col = td.find_all('td', class_=\"table-body__cell rankings-table__team\")\n",
    "        Match_col = td.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "        Point_col= td.find_all('td', class_=\"table-body__cell u-center-text\")\n",
    "        Ratings_col= td.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    " \n",
    "        for i in Team_col:\n",
    "            Tname = i.text.strip()\n",
    "            Team_Name.append(Tname)\n",
    "            #del Team_Name[19:]\n",
    "        \n",
    "        for i in Match_col:\n",
    "            \n",
    "            Matches.append(Match_col[0].text)\n",
    "            Points.append(Match_col[1].text)\n",
    "            Match_col.pop(0)\n",
    "            #del Points[19:38]\n",
    "        \n",
    "                    \n",
    "        for i in Ratings_col:\n",
    "            rating=i.text.strip()\n",
    "            Ratings.append(rating)\n",
    "            \n",
    "            \n",
    "        \n",
    "    #saving the data in Dataframe\n",
    "    teams = pd.DataFrame({'Team_Name':Team_Name,\n",
    "                       'YMatches':Matches,\n",
    "                       'Points':Points,'Ratings':Ratings\n",
    "                       })\n",
    "\n",
    "    print(teams[0:10])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC Ranking for ODI teams International Cricket Council\n",
      "          Team_Name YMatches Points Ratings\n",
      "0  South Africa\\nSA       24  2,828     118\n",
      "1      England\\nENG       17  1,993     117\n",
      "2        India\\nIND       20  2,226     111\n",
      "3   New Zealand\\nNZ       18  1,696      94\n",
      "4   West Indies\\nWI       12  1,025      85\n",
      "5     Pakistan\\nPAK       15  1,101      73\n",
      "6   Bangladesh\\nBAN        5    306      61\n",
      "7     Sri Lanka\\nSL       11    519      47\n",
      "8      Ireland\\nIRE        2     25      13\n"
     ]
    }
   ],
   "source": [
    "Top10ODIWomenTeam(\"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. (ii) scraping top 10 women ODI players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top10WomenODI(url):\n",
    "    Batsman_Name = []\n",
    "    Team = []\n",
    "    Ratings=[]\n",
    "    \n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    " \n",
    "    print(soup.title.text)\n",
    " \n",
    "    tbody = soup.tbody\n",
    "    table_rows = tbody.find_all('tr')\n",
    " \n",
    "    for td in table_rows:\n",
    "        batsman_col = td.find_all('td', class_=\"table-body__cell name\")\n",
    "        Team_col = td.find_all('span', class_=\"table-body__logo-text\")\n",
    "        Ratings_col= td.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    " \n",
    "        for i in batsman_col:\n",
    "            name = i.a.text\n",
    "            Batsman_Name.append(name)\n",
    "            \n",
    "        for i in Team_col:\n",
    "            team=i.text.strip()\n",
    "            Team.append(team)\n",
    "            \n",
    "        for i in Ratings_col:\n",
    "            rating=i.text.strip()\n",
    "            Ratings.append(rating)\n",
    "            \n",
    "            \n",
    "       \n",
    "    #saving the data in Dataframe\n",
    "    batsman = pd.DataFrame({'Batsman Name':Batsman_Name,\n",
    "                       'Team':Team,\n",
    "                       'Ratings':Ratings\n",
    "                       })\n",
    "\n",
    "    print(batsman)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC ODI Match Player Rankings International Cricket Council\n",
      "        Batsman Name Team Ratings\n",
      "0     Tammy Beaumont  ENG     765\n",
      "1        Meg Lanning  AUS     749\n",
      "2    Stafanie Taylor   WI     746\n",
      "3       Alyssa Healy  AUS     741\n",
      "4  Amy Satterthwaite   NZ     740\n",
      "5    Smriti Mandhana  IND     719\n",
      "6    Laura Wolvaardt   SA     699\n",
      "7        Mithali Raj  IND     693\n",
      "8       Ellyse Perry  AUS     691\n"
     ]
    }
   ],
   "source": [
    "Top10WomenODI(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. (iii) scraping top 10 alrouders ODI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top10WomenAlrouderODI(url):\n",
    "    Alrounder_Name = []\n",
    "    Team = []\n",
    "    Ratings=[]\n",
    "    \n",
    "    source = requests.get(url).text\n",
    "    soup = BeautifulSoup(source, 'lxml')\n",
    " \n",
    "    print(soup.title.text)\n",
    " \n",
    "    tbody = soup.tbody\n",
    "    table_rows = tbody.find_all('tr')\n",
    "    main_div=soup.find_all('div',{\"class\":\"rankings-block__container\",\"data-cricket-role\":\"all_round\"})\n",
    "        \n",
    "    for td in main_div:\n",
    "        Alrounder_col = td.find_all('td', class_=\"table-body__cell name\")\n",
    "        Team_col = td.find_all('span', class_=\"table-body__logo-text\")\n",
    "        Ratings_col= td.find_all('td', class_=\"table-body__cell u-text-right rating\")\n",
    " \n",
    "        for i in Alrounder_col:\n",
    "            name = i.a.text\n",
    "            Alrounder_Name.append(name)\n",
    "            \n",
    "        for i in Team_col:\n",
    "            team=i.text.strip()\n",
    "            Team.append(team)\n",
    "            \n",
    "        for i in Ratings_col:\n",
    "            rating=i.text.strip()\n",
    "            Ratings.append(rating)\n",
    "            \n",
    "            \n",
    "    #saving the data in Dataframe\n",
    "    Alrounder = pd.DataFrame({'Alrounder Name':Alrounder_Name,\n",
    "                       'Team':Team,\n",
    "                       'Ratings':Ratings\n",
    "                       })\n",
    "\n",
    "    print(Alrounder[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ICC ODI Match Player Rankings International Cricket Council\n",
      "     Alrounder Name Team Ratings\n",
      "0   Stafanie Taylor   WI     410\n",
      "1    Marizanne Kapp   SA     390\n",
      "2     Deepti Sharma  IND     357\n",
      "3    Natalie Sciver  ENG     349\n",
      "4     Jess Jonassen  AUS     301\n",
      "5     Sophie Devine   NZ     274\n",
      "6  Dane van Niekerk   SA     252\n",
      "7   Katherine Brunt  ENG     236\n",
      "8  Ashleigh Gardner  AUS     223\n"
     ]
    }
   ],
   "source": [
    "Top10WomenAlrouderODI(\"https://www.icc-cricket.com/rankings/womens/player-rankings/odi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.  scraping Product Name, Price, Image URL and Average Rating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PhonesBelow20000(url):\n",
    "    \n",
    "    import re\n",
    "    Product_Name=[]\n",
    "    Price=[]\n",
    "    Image=[]\n",
    "    Ratings=[]\n",
    "    \n",
    "    # Getting English translated titles from the movies\n",
    "    headers = {'Accept-Language': 'en-US, en;q=0.5'}\n",
    "    \n",
    "    if requests.get(url):\n",
    "        page=requests.get(url,headers=headers)\n",
    "        print(page)\n",
    "        soup=BeautifulSoup(page.text,'html.parser')\n",
    "        \n",
    "        product_div=soup.find_all('div',class_='a-section a-spacing-medium')\n",
    "        \n",
    "        for container in product_div:\n",
    "            #scraping product name\n",
    "            pname=container.find('span',class_=\"a-size-medium a-color-base a-text-normal\")\n",
    "            Product_Name.append(pname)\n",
    "            \n",
    "            # Scraping the price\n",
    "            price = container.find('span', class_='a-price-whole')\n",
    "            Price.append(price)\n",
    "            #Book_Name.strip()\n",
    "            \n",
    "            #scraping image\n",
    "            # Extract and store in top_items according to instructions on the left\n",
    "            images = container.select('img',class_=\"s-image\")\n",
    "            for image in images:\n",
    "                src = image.get('src')\n",
    "                alt = image.get('alt')\n",
    "                Image.append({\"src\": src,\"alt\":alt})\n",
    "                #images = container.find('div', class_=\"s-image\")['style':'url']\n",
    "                #Image.append(images)\n",
    "            \n",
    "            ratings=container.find('span',class_='a-icon-alt')\n",
    "            Ratings.append(ratings)\n",
    "            #Genre.strip()\n",
    "            \n",
    "        print(len(Product_Name),len(Price),len(Image),len(Ratings)) \n",
    "        phones=pd.DataFrame({'Product Name':Product_Name ,'Price':Price,\n",
    "                           'Image URL' : Image,'Ratings': Ratings})    \n",
    "        \n",
    "        print(phones)\n",
    "    else:\n",
    "        print(\"Web Access Denied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "24 24 24 24\n",
      "                                         Product Name     Price  \\\n",
      "0   [Redmi 9A (Nature Green, 2GB Ram, 32GB Storage...   [6,799]   \n",
      "1         [Redmi 9 (Sky Blue, 4GB RAM, 64GB Storage)]   [8,799]   \n",
      "2   [Redmi Note 9 Pro Max (Interstellar Black, 6GB...  [14,999]   \n",
      "3                                                None      None   \n",
      "4                                                None      None   \n",
      "5                                                None      None   \n",
      "6                                                None      None   \n",
      "7                                                None      None   \n",
      "8                                                None      None   \n",
      "9                                                None      None   \n",
      "10                                               None      None   \n",
      "11  [Samsung Galaxy M31 (Ocean Blue, 6GB RAM, 128G...  [16,499]   \n",
      "12  [Redmi 9A (Nature Green, 3GB Ram, 32GB Storage...   [7,499]   \n",
      "13  [Redmi Note 9 (Pebble Grey, 4GB RAM 64GB Stora...  [10,999]   \n",
      "14  [Oppo A31 (Mystery Black, 6GB RAM, 128GB Stora...  [11,990]   \n",
      "15  [Redmi 9 Prime (Space Blue, 4GB RAM, 64GB Stor...   [9,499]   \n",
      "16  [Samsung Galaxy M31s (Mirage Blue, 6GB RAM, 12...  [18,499]   \n",
      "17  [Samsung Galaxy M01 Core (Black, 2GB RAM, 32GB...   [6,199]   \n",
      "18  [Redmi 9A (Sea Blue, 2GB Ram, 32GB Storage) | ...   [6,799]   \n",
      "19  [Redmi 9A (Midnight Black, 2GB RAM, 32GB Stora...   [6,799]   \n",
      "20  [Redmi 9 Prime (Sunrise Flare, 4GB RAM, 64GB S...   [9,499]   \n",
      "21  [Samsung Galaxy M12 (Blue,4GB RAM, 64GB Storag...  [10,999]   \n",
      "22  [Samsung Galaxy M12 (Blue,6GB RAM, 128GB Stora...  [13,499]   \n",
      "23  [Samsung Galaxy M12 (White,4GB RAM, 64GB Stora...  [10,999]   \n",
      "\n",
      "                                            Image URL               Ratings  \n",
      "0   {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "1   {'src': 'https://m.media-amazon.com/images/I/7...  [4.1 out of 5 stars]  \n",
      "2   {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "3   {'src': 'https://images-na.ssl-images-amazon.c...                  None  \n",
      "4   {'src': 'https://images-eu.ssl-images-amazon.c...                  None  \n",
      "5   {'src': 'https://images-na.ssl-images-amazon.c...                  None  \n",
      "6   {'src': 'https://images-eu.ssl-images-amazon.c...                  None  \n",
      "7   {'src': 'https://images-na.ssl-images-amazon.c...                  None  \n",
      "8   {'src': 'https://images-eu.ssl-images-amazon.c...                  None  \n",
      "9   {'src': 'https://images-na.ssl-images-amazon.c...                  None  \n",
      "10  {'src': 'https://images-eu.ssl-images-amazon.c...                  None  \n",
      "11  {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "12  {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "13  {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "14  {'src': 'https://m.media-amazon.com/images/I/7...  [4.1 out of 5 stars]  \n",
      "15  {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "16  {'src': 'https://m.media-amazon.com/images/I/6...  [4.3 out of 5 stars]  \n",
      "17  {'src': 'https://m.media-amazon.com/images/I/7...  [3.5 out of 5 stars]  \n",
      "18  {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "19  {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "20  {'src': 'https://m.media-amazon.com/images/I/7...  [4.2 out of 5 stars]  \n",
      "21  {'src': 'https://m.media-amazon.com/images/I/7...  [5.0 out of 5 stars]  \n",
      "22  {'src': 'https://m.media-amazon.com/images/I/7...  [5.0 out of 5 stars]  \n",
      "23  {'src': 'https://m.media-amazon.com/images/I/7...  [5.0 out of 5 stars]  \n"
     ]
    }
   ],
   "source": [
    "PhonesBelow20000(\"https://www.amazon.in/s?k=mobiles+under+20000&ref=nb_sb_noss_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most of the time , access is denied for amazon.in. \n",
    "page=requests.get(\"https://www.amazon.in/s?k=mobiles+under+20000&ref=nb_sb_noss_2\")\n",
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Weather forecast of San Francisco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# period, short description, temperature and description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WeatherForecast(url):\n",
    "    \n",
    "    Period=[]\n",
    "    ShortDesc=[]\n",
    "    Temprature=[]\n",
    "    Description=[]\n",
    "    \n",
    "    # Getting English translated titles from the movies\n",
    "    headers = {'Accept-Language': 'en-US, en;q=0.5'}\n",
    "    \n",
    "    if requests.get(url):\n",
    "        page=requests.get(url,headers=headers)\n",
    "        print(page)\n",
    "        soup=BeautifulSoup(page.text,'html.parser')\n",
    "        \n",
    "        weather_div=soup.find_all('li',class_='forecast-tombstone')\n",
    "        detailDesc_div=soup.find_all('div',class_='row row-odd row-forecast')\n",
    "        for container in weather_div:\n",
    "            #scraping day\n",
    "            period=container.find('p',class_='period-name')\n",
    "            Period.append(period)\n",
    "            del Period[7:]\n",
    "            \n",
    "            # Scraping the ShortDescription\n",
    "            sDesc = container.find('p', class_='short-desc')\n",
    "            ShortDesc.append(sDesc)\n",
    "            del ShortDesc[7:]\n",
    "            \n",
    "            #scraping Temprature\n",
    "            temp=container.find('p',class_={'temp temp-high','temp temp-low'})\n",
    "            Temprature.append(temp)\n",
    "            del Temprature[7:]\n",
    "        \n",
    "        for i in detailDesc_div:\n",
    "    \n",
    "            #scraping Description\n",
    "            desc=i.find('div',class_='col-sm-10 forecast-text')\n",
    "            Description.append(desc)\n",
    "            #del Description[8:] \n",
    "            \n",
    "        print(len(Period),len(ShortDesc),len(Temprature),len(Description))\n",
    "            \n",
    "        weather=pd.DataFrame({'Day':Period ,'Short Description':ShortDesc,\n",
    "                           'Temperature' : Temprature,'Description': Description})    \n",
    "        print(weather)\n",
    "    else:\n",
    "        print(\"Web Access Denied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "7 7 7 7\n",
      "                      Day Short Description    Temperature  \\\n",
      "0         [Today, [], []]    [Mostly Sunny]  [High: 65 °F]   \n",
      "1       [Tonight, [], []]    [Mostly Clear]   [Low: 47 °F]   \n",
      "2       [Tuesday, [], []]           [Sunny]  [High: 69 °F]   \n",
      "3    [Tuesday, [], Night]           [Clear]   [Low: 49 °F]   \n",
      "4     [Wednesday, [], []]           [Sunny]  [High: 70 °F]   \n",
      "5  [Wednesday, [], Night]    [Mostly Clear]   [Low: 49 °F]   \n",
      "6      [Thursday, [], []]           [Sunny]  [High: 65 °F]   \n",
      "\n",
      "                                         Description  \n",
      "0  [Mostly sunny, with a high near 65. West wind ...  \n",
      "1  [Sunny, with a high near 69. North wind 7 to 1...  \n",
      "2  [Sunny, with a high near 70. Light and variabl...  \n",
      "3                      [Sunny, with a high near 65.]  \n",
      "4                      [Sunny, with a high near 66.]  \n",
      "5                      [Sunny, with a high near 69.]  \n",
      "6                      [Sunny, with a high near 72.]  \n"
     ]
    }
   ],
   "source": [
    "WeatherForecast(\"https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YFg36JMzau4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
